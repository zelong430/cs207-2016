{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Databases 2\n",
    "\n",
    "### OR\n",
    "\n",
    "## Hash tables and their use in Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do you care?\n",
    "\n",
    "- you will see many databases in your career\n",
    "- you will code SQL\n",
    "- you will have to deal with systematic storage of structured and unstructured data at some point\n",
    "- and you will have to access this data from it storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some databases\n",
    "\n",
    "- **PostgreSQL** and **sqlite** are relational database management: tuples in data rows and strictly enforced column types. Schema.\n",
    "- **Riak** distributed, fault-tolerant key-value database, inspired by Amazon Dynamo, low latency. A storage engine for it is *bitcask*, based on the deas from the database we wrote last time. No schema.\n",
    "- **HBase**: large database (big data), columnar, scalable, corenerstone for OLAP, fault tolerant, used with Hadoop, based on Google's BigTable\n",
    "- **Mongodb** is a document database, storing JSON documents, schemaless\n",
    "- **Neo4j** is a graph database, stores relationship or edges between nodes. Great for semantic web type stuff\n",
    "- **redis** : data structure server, fast, transactional, can be used for queue, pub/sub, sorted sets, bloom filters, expiration, replication, but not surability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polyglot persistence\n",
    "\n",
    "An example from 7 databases in 7 weeks:\n",
    "\n",
    ">We want to store a list of musical band names, the artists who per- formed in those bands, and any number of roles each artist played in the band, from lead singer to backup keytar player. Each of three databases— Redis, CouchDB, and Neo4j—will handle a different aspect of our band management system.\n",
    "\n",
    ">Redis plays three important roles in our system: to assist in data populating CouchDB, as a cache for recent Neo4j changes, and as a quick lookup for partial value searches. Its speed and ability to store multiple data formats make it well suited for population, and its built-in expiry policies are perfect for handling cached data.\n",
    "\n",
    ">CouchDB is our system of record (SOR), or authoritative data source. CouchDB’s document structure is an easy way to store band data with nested artist and role information, and we will take advantage of the Changes API in CouchDB to keep our third data source in sync.\n",
    "\n",
    ">Neo4j is our relationship store. Although querying the CouchDB SOR directly is perfectly reasonable, a graph datastore allows us a simplicity and speed in walking node relationships that other databases have a difficult time matching. We’ll store relationships between bands, band members, and the roles the members play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From last time\n",
    "\n",
    "![](https://dl.dropboxusercontent.com/u/75194/hashmaplog.png)\n",
    "\n",
    "- in the dict in memory, store a file offset instead\n",
    "- this \"HEAP\" file is an append only file, and thus also acts as a \"LOG\"(WAL)\n",
    "- if you update, simply append a new entry and change the offset in the dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- this is what bitcask in Riak does ( http://basho.com/wp-content/uploads/2015/05/bitcask-intro.pdf)\n",
    "- what if file becomes too large?\n",
    "\n",
    "On disk:\n",
    "\n",
    "![](https://dl.dropboxusercontent.com/u/75194/riak1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In memory:\n",
    "![](https://dl.dropboxusercontent.com/u/75194/riak2.png)\n",
    "\n",
    "(from riak bitcask intro at http://basho.com/wp-content/uploads/2015/05/bitcask-intro.pdf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- deletion is done by writing a tombstone record\n",
    "- break the file into segments. Each segment, once written, the kv pairs are never changed. \n",
    "\n",
    "How do we not run out of disk space>\n",
    "\n",
    "- run compaction to throw away dupes from segments and merge them into a NEW file; delete old files\n",
    "- tombstone means merging process can discard previous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://dl.dropboxusercontent.com/u/75194/compactionmerge.png)\n",
    "\n",
    "\n",
    "- Process model: only one writer thread. Many readers.\n",
    "- Maintain a hashmap per segment and search these in order from most recent to least recent.\n",
    "- bitcask will store hashmap snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are these hashmaps we talk about?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Hash table basics\n",
    "\n",
    "Hash tables are a great for making dictionaries.\n",
    "\n",
    "The basic idea is that once u have an index, looking something up in an array is O(1). \n",
    "Hash tables consist of four parts:\n",
    "1. Keys\n",
    "2. Values\n",
    "3. A hash function\n",
    "4. A storage array\n",
    "\n",
    "![Hash Table Diagram](hash_overview.png)\n",
    "\n",
    "The basic idea is that a hash function provides a constant-time approximation of where to find or store a particular key-value pair. In the common case, the key-value pair can be found or stored at that location. In the uncommon case, the function returned the same value for some other key, so some other location must be searched or used to complete the operation. When a hash function returns the same value for two distinct keys, it is called a collision, and the mechanism to recover is called collision resolution.\n",
    "\n",
    "Indeed, there does not even need to be a set of values. It might just be a bunch of keys. In such a way, a hash table can be used to implement a set: the same values hashes to the same index so there are no repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is this hash function? It is a function that, given your key, and the multitude of possible keys, maps the key to an integer representing an index. For example, suppose your keys are integers k:\n",
    "\n",
    "$$f(k) = k\\,mod\\,11$$\n",
    "\n",
    "![](http://interactivepython.org/courselib/static/pythonds/_images/hashtable2.png)\n",
    "\n",
    "(example from interactivepython.org)\n",
    "\n",
    "A perfect hash function would map each key to a separate index. Hard to do and certainly not possible when u dont know the keys ahead of time. In the hash function above, 66 and 44 both map to 0.\n",
    "\n",
    "Suppose we were puuting in (54,26,93,17,77,31,44,55,20). Then we'd have **collision** when we'd try to put 44 in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to deal with this is to use open addressing:\n",
    "\n",
    "![](http://interactivepython.org/courselib/static/pythonds/_images/linearprobing1.png)\n",
    "\n",
    "Here we put the 44 into the next available spot, say after the 77. This method does lead to clustering but is often used. Then 20 should go in slot 9 but thats used by 31 so we resort to *linear probing* from the beginning to find an empty slot and put it there.\n",
    "\n",
    "We can skip finite numbers while probing, or even have a probing function. The point is that the process must be repeatable so we can \"get\" the value for a key later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The other way to do this is to create a linked list at each array slot and add all collided keys into that linked list. This is called **chaining**.\n",
    "\n",
    "![](http://interactivepython.org/courselib/static/pythonds/_images/chaining.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general you will want a hash function to map a key to a large integer. If $\\alpha$is the size of the alphabet using which a string S is written, and char(c) is a function mapping each letter in the alphabet to a unique integer from 0 to $\\alpha  - 1$.\n",
    "\n",
    "Then,\n",
    "\n",
    "$$H(S) = \\sum_{i=0}^{sz(S) - 1} \\alpha^{sz(S) - (i+1)} char(i)$$\n",
    "\n",
    "maps each string to a unique but large integer by treating each character as a digit in a base-$\\alpha$ numerical system.\n",
    "\n",
    "These intergers will overflow our size (say) m array of slots in the hash table, so we now do:\n",
    "\n",
    "$$H(S)\\,mod\\,m$$. One can show that if m is chosen well (for example a large prime not too close to $2^{\\alpha} - 1$, the resulting hash values will be fairly uniformly distributed.\n",
    " \n",
    "To avoid collisions, chaining seems to be the natural thing to do, but devotes considerable memory to pointers, memory better used at making m larger. But open addressing means that we must systematically do some multi hop searching on a run of indexes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So implicitly we have asked for:\n",
    "\n",
    "1. If two objects are equal, then their hashes should be equal.\n",
    "2. If two objects have the same hash, then they are likely to be the same object. (modulo collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With all this you might think that the dunder `__hash__` delegated to by python for the `hash` function is a hash function that tries to uniformy distribute its contents. This turns out to be not be true, a decision made from the practical observation that often hash table keys have some \"systematic\" ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(1), hash(2), hash(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5979502230166123623, -7224185177662446553, -7128687885686014242)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash('a'), hash('b'), hash('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6420c1e61a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "hash([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The python hashing implementation can be seen at [dictobject.c](http://svn.python.org/projects/python/trunk/Objects/dictobject.c). There are some great notes on the hashing algorithm there, from which I quote:\n",
    "\n",
    "```c\n",
    "Major subtleties ahead:  Most hash schemes depend on having a \"good\" hash\n",
    "function, in the sense of simulating randomness.  Python doesn't:  its most\n",
    "important hash functions (for strings and ints) are very regular in common\n",
    "cases:\n",
    "\n",
    ">>> map(hash, (0, 1, 2, 3))\n",
    "[0, 1, 2, 3]\n",
    ">>> map(hash, (\"namea\", \"nameb\", \"namec\", \"named\"))\n",
    "[-1658398457, -1658398460, -1658398459, -1658398462]\n",
    ">>>\n",
    "\n",
    "This isn't necessarily bad!  To the contrary, in a table of size 2**i, taking\n",
    "the low-order i bits as the initial table index is extremely fast, and there\n",
    "are no collisions at all for dicts indexed by a contiguous range of ints.\n",
    "The same is approximately true when keys are \"consecutive\" strings.  So this\n",
    "gives better-than-random behavior in common cases, and that's very desirable.\n",
    "\n",
    "OTOH, when collisions occur, the tendency to fill contiguous slices of the\n",
    "hash table makes a good collision resolution strategy crucial.  Taking only\n",
    "the last i bits of the hash code is also vulnerable:  for example, consider\n",
    "[i << 16 for i in range(20000)] as a set of keys.  Since ints are their own\n",
    "hash codes, and this fits in a dict of size 2**15, the last 15 bits of every\n",
    "hash code are all 0:  they *all* map to the same table index.\n",
    "\n",
    "But catering to unusual cases should not slow the usual ones, so we just take\n",
    "the last i bits anyway.  It's up to collision resolution to do the rest.  If\n",
    "we *usually* find the key we're looking for on the first try (and, it turns\n",
    "out, we usually do -- the table load factor is kept under 2/3, so the odds\n",
    "are solidly in our favor), then it makes best sense to keep the initial index\n",
    "computation dirt cheap.\n",
    "\n",
    "The first half of collision resolution is to visit table indices via this\n",
    "recurrence...\n",
    "```\n",
    "\n",
    "A good resource to see the whole story is http://www.laurentluce.com/posts/python-dictionary-implementation/ . Knowing C will help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python dictionaries\n",
    "\n",
    "Python `dict`s are hash tables. We're going to understand how they operate internally.\n",
    "\n",
    "As we've already discussed, Python data structures are largely defined by the interfaces they present. There are two interfaces we care about here:\n",
    "\n",
    " - Objects that act like dictionaries\n",
    " - Objects that can act as key for dictionaries\n",
    " \n",
    "Just like sequences and iterables, the interface for Python dictionaries can be described by a small set of special methods. The easiest way to understand this is to match Python statements involving dictionaries with the special methods they call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "### All of these pairs of statements are equivalent.\n",
    "\n",
    "# Setting an item\n",
    "dictionary['key1'] = 'value1'\n",
    "dictionary.__setitem__('key2', 'value2')\n",
    "\n",
    "# Getting an item\n",
    "x = dictionary['key1']\n",
    "x = dictionary.__getitem__('key2')\n",
    "\n",
    "# Get the size of an item\n",
    "len(dictionary)\n",
    "dictionary.__len__()\n",
    "\n",
    "# Iterating over a dictionary\n",
    "[key for key in dictionary]\n",
    "[key for key in dictionary.__iter__()]\n",
    "\n",
    "# Deleting an item\n",
    "del dictionary['key1']\n",
    "dictionary.__delitem__('key2')\n",
    "\n",
    "# Checking at item (OPTIONAL)\n",
    "'key1' in dictionary\n",
    "dictionary.__contains__('key2')\n",
    "for key in dictionary: # Fallback behavior, if __contains__ is not defiend\n",
    "    if key=='key1':\n",
    "        True\n",
    "else: # You can have else blocks on for-loops in Python\n",
    "    False\n",
    "\n",
    "# Default values (OPTIONAL)\n",
    "# Normal dicts do not implement this feature\n",
    "# x = dictionary['missing-key']\n",
    "# x = dictionary.__missing__('missing-key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dictionary keys\n",
    "\n",
    "Dictionary keys in Python can be any object that satisfies the interface convention.\n",
    "\n",
    "A common misconception is that dictionary keys must be immutable.\n",
    "\n",
    "In actuality, Python dicts define an interface just like everything else. There are two relavent special methods:\n",
    "\n",
    "1. `__hash__`: returns an integer. This will eventually get converted by Python to an index.\n",
    "2. `__eq__`: compares two objects for equality. This is how collisions are detected.\n",
    "\n",
    "In general, immutable built-in types (like numbers and tuples) have `__hash__` methods defined, and built-in mutable types (like lists and dicts) have `__hash__` set to `None`.\n",
    "\n",
    "Let's see some examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Two things to remember:\n",
    "\n",
    " - User-defined classes inherit a `__hash__` from `object` which returns a hash based on the identity of the object.\n",
    " - The implementation of `__eq__` inherited from `object` compares the identity of two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class UtilityMethodsMixin(): \n",
    "    def __init__(self, v):\n",
    "        self.set(v)\n",
    "    def set(self, v):\n",
    "        self.v = v\n",
    "    def __repr__(self):\n",
    "        return '<OBJ|id:'+str(id(self))+'|v:'+str(self.v)+'>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First up, `hash(A)==hash(A)`. Hashes should be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class InconsistentHashable(UtilityMethodsMixin):\n",
    "    def __hash__(self):\n",
    "        obtained = random.randint(0,1000)\n",
    "        print(\"ob\", obtained)\n",
    "        return obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OBJ|id:4363907480|v:0>\n",
      "ob 711\n",
      "ob 679\n",
      "ob 108\n",
      "711 679 108\n",
      "----\n",
      "ob 389\n",
      "ob 34\n",
      "ob 544\n",
      "{<OBJ|id:4363907480|v:0>: 'z', <OBJ|id:4363907480|v:0>: 'y', <OBJ|id:4363907480|v:0>: 'x'}\n",
      "ob 30\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "A = InconsistentHashable(v=0)\n",
    "print(A)\n",
    "print(hash(A), hash(A), hash(A))\n",
    "print('----')\n",
    "dictionary = {}\n",
    "dictionary[A] = 'x'\n",
    "dictionary[A] = 'y'\n",
    "dictionary[A] = 'z'\n",
    "print(dictionary)\n",
    "print( A in dictionary )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next: Normally, `hash(A)!=hash(B)` if `A!=B`. We normally want to *avoid* collisions in hash tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class NormalHashable(UtilityMethodsMixin):\n",
    "    def __hash__(self):\n",
    "        return hash(id(self))\n",
    "    def __eq__(self, other):\n",
    "        return self.v==other.v\n",
    "class SlowHashable(UtilityMethodsMixin):\n",
    "    def __hash__(self):\n",
    "        return 0\n",
    "    def __eq__(self, other):\n",
    "        return self.v==other.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.08 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dictionary = {}\n",
    "for i in range(1000):\n",
    "    A = NormalHashable(i)\n",
    "    dictionary[A] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 164 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dictionary = {}\n",
    "for i in range(1000):\n",
    "    A = SlowHashable(i)\n",
    "    dictionary[A] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Constantly causing collisions *really* slows things down.\n",
    "\n",
    "Finally, the strange one: \"`A==B` implies `hash(A)==hash(B)`. If two objects are equal, they should always hash to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class StrangeHashable(UtilityMethodsMixin):\n",
    "    def __hash__(self):\n",
    "        return id(self)%10\n",
    "    def __eq__(self, other):\n",
    "        return self.v==other.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OBJ|id:4363910000|v:0> <OBJ|id:4363907760|v:0> <OBJ|id:4363907872|v:0>\n",
      "(A==B) True  (hash(A)==hash(B)) True\n",
      "(B==C) True  (hash(B)==hash(C)) False\n",
      "{<OBJ|id:4363910000|v:0>: 'a'}\n",
      "{<OBJ|id:4363910000|v:0>: 'b'}\n",
      "{<OBJ|id:4363910000|v:0>: 'b', <OBJ|id:4363907872|v:0>: 'c'}\n"
     ]
    }
   ],
   "source": [
    "A = [A for A in [StrangeHashable(v=0) for _ in range(0,50)] if hash(A)==0][0] # Find an instance which hashes to 0\n",
    "B = [B for B in [StrangeHashable(v=0) for _ in range(0,50)] if hash(B)==0][0] # Find an instance which hashes to 0\n",
    "C = [C for C in [StrangeHashable(v=0) for _ in range(0,50)] if hash(C)==2][0] # Find an instance which hashes to 2\n",
    "\n",
    "print(A, B, C)\n",
    "print('(A==B)',A==B, ' (hash(A)==hash(B))',hash(A)==hash(B))\n",
    "print('(B==C)',B==C, ' (hash(B)==hash(C))',hash(B)==hash(C))\n",
    "\n",
    "dictionary = {}\n",
    "dictionary[A] = 'a'\n",
    "print(dictionary)\n",
    "dictionary[B] = 'b'\n",
    "print(dictionary)\n",
    "dictionary[C] = 'c'\n",
    "print(dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** TL;DR: **\n",
    "\n",
    " - `__hash__` and `__eq__` govern `dict` behavior in Python.\n",
    " - If you're going to implement a class which can act like a dictionary key:\n",
    "  - `hash(A)==hash(A)`\n",
    "  - Normally, `hash(A)!=hash(B)` if `A!=B`\n",
    "  - `A==B` implies `hash(A)==hash(B)`\n",
    "  \n",
    "More such fun at http://www.asmeurer.com/blog/posts/what-happens-when-you-mess-with-hashing-in-python/, which also notes that:\n",
    "\n",
    ">in Python 3, if you override `__eq__`, it automatically sets `__hash__` to None, making the object unhashable. You need to manually override `__hash__` to make it hashable again. But that's as far as Python goes in enforcing these rules, as we will see below. In particular, Python will never actually check that your `__hash__` actually agrees with your `__eq__`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSM Tree\n",
    "\n",
    "Why is appending in our Riak'ish database a good strategy?\n",
    "\n",
    "- sequential writes are faster than random writes on both old disks and SSDs\n",
    "- append-only or immutable files are safer in a crash when updating a value\n",
    "- but hashmaps perform poorly on disk (random IO)\n",
    "- and range queries are not efficient\n",
    "\n",
    "This leads us to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "The big change is that we now write our heap files in SORTED key-value order.\n",
    "\n",
    "What? Does this not break our nice LOG format? And the ability to use sequential files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSM Tree\n",
    "\n",
    "1. when a write comes in add it first to the WAL.\n",
    "2. then to an in-memory balanced binary tree tree structure, called a memtable, for example a red-black tree. The WAL above's sole purpose is to reconstruct this tree in the face of a crash\n",
    "3. At some duration or number-of-writes threshold we write the tree into a SSTable (sorted string table) file. This becomes the most recent segment of the database, and the memtable is cleared out for reuse. Because the memtable was sorted, the sstable is sorted as well. A bitcask style key-offset in-memory hashmap is used in a sparse way to remember some keys. The rest can be found by linear scanning from that offset onwards\n",
    "4. we run merging and compaction in the background in the spirit of a mergesort and to discard overwritten or deleted values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Compaction and merging\n",
    "\n",
    "![](https://dl.dropboxusercontent.com/u/75194/lsmmerge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### In memory sparse hashmap\n",
    "\n",
    "![](https://dl.dropboxusercontent.com/u/75194/lsmsparseindex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How does it work?\n",
    "\n",
    "```\n",
    "    BF--->memtable--->in-memory sparse-hashmaps--->\n",
    "        sstable segment--->sstable segment--->....\n",
    "```\n",
    "\n",
    "Searches go from memtable to these segments, one by one based on recent-ness, with a bloom filter being used to tell if the key was never there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bloom Filter\n",
    "\n",
    "In the LSM tree, a bloom filter takes care of asking, is the key in our system at all. Its a strange data structure: it can answer in the affirmative that something is not in it, but only probabilistically that something is in it.\n",
    "\n",
    "What is a bloom filter?\n",
    "\n",
    "Basically its a hash table. The hash function computes a index, and the value corresponding to that index is a bit either set to 1 or 0. (In python this may be done by installing the bitarray or bitstring module).\n",
    "\n",
    "One might ask, why not just use a set? The answer is, what if we want, as in the LSM tree, only one of the answers, and what if we want this to me a compact in-memory data structure, also true for a LSM tree. In a similar way, browsers use this to blacklist malaware sites.\n",
    "\n",
    "```\n",
    "pip install bitarray\n",
    "pip install mmh3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are two key numbers in a bloom filter\n",
    "\n",
    "1. the number of hash functions: can range from a few to a dozen. These could be different functions or the same functions with different seeds. A good hash function spreads keys uniformly\n",
    "2. thie size of the array: the number of bits we have. This is application dependent\n",
    "\n",
    "The math for a bloom filter can be found on wikipedia (https://en.wikipedia.org/wiki/Bloom_filter) : we will not go into it here.\n",
    "\n",
    "We'll reproduce an example from http://www.maxburstein.com/blog/creating-a-simple-bloom-filter/ where the murmur hash funcrion is used (coming up with hash functions yourself is not easy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "import mmh3\n",
    " \n",
    "class BloomFilter:\n",
    "    \n",
    "    def __init__(self, size, hash_count):\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "        \n",
    "    def add(self, string):\n",
    "        for seed in range(self.hash_count):\n",
    "            result = mmh3.hash(string, seed) % self.size\n",
    "            self.bit_array[result] = 1\n",
    "        \n",
    "    def lookup(self, string):\n",
    "        for seed in range(self.hash_count):\n",
    "            result = mmh3.hash(string, seed) % self.size\n",
    "            if self.bit_array[result] == 0:\n",
    "                return \"Nope\"\n",
    "        return \"Probably\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bf = BloomFilter(100, 4)\n",
    "bf.add(\"rahul\")\n",
    "bf.add(\"rohan\")\n",
    "bf.add(\"anthony\")\n",
    "bf.add(\"nicholas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Probably'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.lookup(\"rahul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nope'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.lookup(\"sophie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Range queries are supported because we keep things in sort order.\n",
    "\n",
    "- LevelDB, RocksDB (both embedded), Cassandra, HBase, Lucene are all examples of this append-to-log like approach. Cassandra, HBase and Leveldb use LSM Trees. Lucene's index  uses a key-value structure where the key is a wordand value is the list of docs containing the word. The index is kept in SSTable-like sorted files, \n",
    "and merged in the background as needed.\n",
    "- The second school is the update-in-place school, using overwritable fixed size pages. Btrees are the major example here, but even they can be treated in a functional append-only style, as is done in lmdb and boltdb.\n",
    "\n",
    "\n",
    "More about NOSQL dbs at https://en.wikipedia.org/wiki/NoSQL ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### B-tree vs LSM tree\n",
    "\n",
    "- critical difference: btrees update in-place!\n",
    "- comparable on random reads\n",
    "- compaction can affect performance in LSM trees\n",
    "- LSM tree good on random writes as it makes the writes sequential\n",
    "- LSM true and b-tree are both used for transactions\n",
    "- B-tree very good for transactions; at most one place where things are: you just need to lock a section of the tree. But concurrency can be complex as we shall see later and in-place updates are dangerous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transaction Processing or Analytics?\n",
    "\n",
    "- Also known as OLTP vs OLAP/Warehousing\n",
    "- small query size vs aggregates over large ones\n",
    "- random writes from user input vs ordered ETL/stream\n",
    "- end user (amazon site) vs analyst (you)\n",
    "- GB to TB vs TB to PB\n",
    "\n",
    "![](https://dl.dropboxusercontent.com/u/75194/ETL.png)\n",
    "\n",
    "(from designing data intensive applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Row Oriented Storage\n",
    "\n",
    "- heapfile or clustered index is a set of rows\n",
    "- we'll see details of this storage soon\n",
    "- index could be a tree with appropriate pointer to heapfile offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![](https://www.simple-talk.com/iwritefor/articlefiles/1844-f4cc85b0-9ddb-44cc-93ef-a742fcc4f279.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Column oriented storage\n",
    "\n",
    "\n",
    "- store values from each column together in separate storage\n",
    "- lends itself to compression with bitmap indexes and run-length encoding\n",
    "- this involves choosing an appropriate sort order\n",
    "- the index then can be the data (great for IN and AND queries): there is no pointers to \"elsewhere\"\n",
    "- compressed indexes can fit into cache and are usable by iterators\n",
    "- bitwise AND/OR can be done with vector processing\n",
    "- several different sort orders can be redundantly stored\n",
    "- writing is harder: updating a row touches many column files\n",
    "- but you can write an in-memory front sorted store (row or column), and eventually merge onto the disk (Binary Tree!) (Vertica does this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://www.simple-talk.com/iwritefor/articlefiles/1844-4e2482bb-aaff-4ebd-8900-1946560479af.jpeg)\n",
    "\n",
    "(images from https://www.simple-talk.com/sql/database-administration/columnstore-indexes-in-sql-server-2012/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples: Vertica, monetdb, hbase, cassandra, etc. SQL server has a columnar mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some thoughts on usage:\n",
    "\n",
    "- relational databases are good for structured but bad for hierarchicval and unstructured data\n",
    "- key value stored have no additional index (the database is the index) and are very horizontally scalable which means i can add more nodes to my system to improve performance. bad for joins and scans.\n",
    "- columnar databases are good for big data, horizontal scaling\n",
    "- document databases are good for highly variable and unstructured data, that is nevertheless queried only one way like a k-v store\n",
    "- graph databases good for highly connected data such as social networks and semantic web where there are lots of relationships."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
